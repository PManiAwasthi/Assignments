{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "How would you describe TensorFlow in a short sentence? What are its main features? Can\n",
        "you name other popular Deep Learning libraries?"
      ],
      "metadata": {
        "id": "oKESaa0hIQ-t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "It is a multiplatform library used for deep learning and also supports traditional ML, with other functionalities useful during the whole lifecycle of and AI project.\n",
        "Features include:\n",
        "1. easily trainable\n",
        "2. parallel neural network training\n",
        "3. open source\n",
        "4. contains statistical distributions\n",
        "5. layered components\n",
        "6. flexible\n",
        "7. responsive construct\n",
        "\n",
        "other popular DL libraies pytorch, theano, keras.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "gIBevayHIRDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is TensorFlow a drop-in replacement for NumPy? What are the main differences between\n",
        "the two?"
      ],
      "metadata": {
        "id": "OegWLF3XIaY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "I guess it's not actually a replacement as even though TensorFlow does have a NumPy API implemented in it both tensorflow and numpy are used for separate purposes,\n",
        "the numpy is for general purpose computational whereas tensorflow is for developing, maintaining, machine leanring models framework.\n",
        "\n",
        "Tensorflow is different from NumPy by:\n",
        "1. Tensorflow is highly sensitive to datatypes.\n",
        "2. Tensorflow uses function call convention over method meaning functions are called explicitly through library reference rather then from objects.\n",
        "3. np.concatenate renamed to tf.concat\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "AUncb46wIaZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do you get the same result with tf.range(10) and tf.constant(np.arange(10))?"
      ],
      "metadata": {
        "id": "PNqOwdCSIacM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "print(tf.range(10))\n",
        "print(tf.constant(np.arange(10)))\n",
        "\n",
        "\"\"\"\n",
        "the output is same when it comes to value the only difference is the data type of the values in the tensor\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "R6a1jJ45IacN",
        "outputId": "8444b10a-6686-4fc8-803d-1d96c261a7f8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10,), dtype=int32)\n",
            "tf.Tensor([0 1 2 3 4 5 6 7 8 9], shape=(10,), dtype=int64)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can you name six other data structures available in TensorFlow, beyond regular tensors?"
      ],
      "metadata": {
        "id": "dWiEQ1jmIafd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "1. string arrays\n",
        "2. ragged tensors\n",
        "3. sparse tensors\n",
        "4. tensor arrays\n",
        "5. sets\n",
        "6. queues\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "rVAFnZ4CIafe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A custom loss function can be defined by writing a function or by subclassing\n",
        "the keras.losses.Loss class. When would you use each option?"
      ],
      "metadata": {
        "id": "S694GBxSIaiu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "When we want to write a completely new loss function from scratch rather than modilfying a loss function available then we write a function instead of using \n",
        "keras.losses.Loss class.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "g25qp8qXIaiv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly, a custom metric can be defined in a function or a subclass of keras.metrics.Metric.\n",
        "When would you use each option?"
      ],
      "metadata": {
        "id": "T7cxuF4ZIal-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "similarly if we want to make a metrics using some of the already available metric then we use keras.metrics.Metric if not then we can just write a function.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "fwfHoAH9Ial-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When should you create a custom layer versus a custom model?"
      ],
      "metadata": {
        "id": "pFDHaYP9IapR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Making a custom model means to stack the already available layer in different manners and changing their hyperparameters, etc. This is good when we do not have a requirement \n",
        "in which cannot be meet by the built in layers like for image we have Convolution layer, for regression we have dense, etc. But if there is a situation where we need something \n",
        "that the preexisting layers can't provide like some custom functionality for some new formula that we might need then we go for custom layer.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "XQdkNdVOIapS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are some use cases that require writing your own custom training loop?"
      ],
      "metadata": {
        "id": "HwldaYK2Ias5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "When we need to do something with the batching, metrics, loss, function, or optimizers that need to be changed from what is usually not defualt then we use \n",
        "custom training loops.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "ujF5BS-3Ias6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can custom Keras components contain arbitrary Python code, or must they be convertible to\n",
        "TF Functions?"
      ],
      "metadata": {
        "id": "RPYbgIBSIawH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "custom keras components should adhere to the rules listed in TF function rules and stick to TF operations as much as possible which means the should be convertible to TF \n",
        "Functions, in case we need arbitrary code then we need to wrap it in tf.py_function() or set dynamic = True, when creating the custom layer or model.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "OQHxui52IawI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are the main rules to respect if you want a function to be convertible to a TF Function?\n"
      ],
      "metadata": {
        "id": "nWL6eutCIa0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "- For Tensor, the type is parameterized by the Tensor's dtype and shape; ranked shapes are a subtype of unranked shapes; fixed dimensions are a subtype of unknown dimensions\n",
        "\n",
        "- For Variable, the type is similar to Tensor, but also includes a unique resource ID of the variable, necessary to correctly wire control dependencies\n",
        "\n",
        "- For Python primitive values, the type corresponds to the value itself. For example, the TraceType of the value 3 is LiteralTraceType<3>, not int.\n",
        "\n",
        "- For Python ordered containers such as list and tuple, etc., the type is parameterized by the types of their elements; for example, the type of [1, 2] is \n",
        "ListTraceType<LiteralTraceType<1>, LiteralTraceType<2>> and the type for [2, 1] is ListTraceType<LiteralTraceType<2>, LiteralTraceType<1>> which is different.\n",
        "\n",
        "- For Python mappings such as dict, the type is also a mapping from the same keys but to the types of values instead the actual values. For example, the type of {1: 2, 3: 4}, \n",
        "is MappingTraceType<<KeyValue<1, LiteralTraceType<2>>>, <KeyValue<3, LiteralTraceType<4>>>>. However, unlike ordered containers, {1: 2, 3: 4} and {3: 4, 1: 2} have equivalent types.\n",
        "\n",
        "- For Python objects which implement the __tf_tracing_type__ method, the type is whatever that method returns\n",
        "\n",
        "- For any other Python objects, the type is a generic TraceType which uses the object's Python equality and hashing for matching. (Note: It relies on weakref to the object and \n",
        "hence only works as long as the object is in scope/not deleted.)\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "lmWViZ8xIa0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "When would you need to create a dynamic Keras model? How do you do that? Why not\n",
        "make all your models dynamic?"
      ],
      "metadata": {
        "id": "jftfU7DSIa3l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "When we need high flexibility or when we need to use models as regular layers so that they can be combined to build complex architectures. \n",
        "\n",
        "First make class which inherits from tf.keras.models then make the subclasses if you need to use models (or stack of layers) as regular layers, \n",
        "or define a architecture in the init methods after which write the final architecture using the objects or the architecture defined in the call() methods and return \n",
        "the final model.\n",
        "\n",
        "Making a complex model means its going to take that much time to train, a lot of resouces and might be slow in output generation. Many of the problems do not require \n",
        "complex model to implemented as all the layers are optimized to work with a large number of AI tasks.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "25oa6piwIa3m",
        "outputId": "370aefb3-07b3-4f42-dfdb-87253b3b36ec"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hEoH2sfhdNGZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}