{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "What are the main tasks that autoencoders are used for?"
      ],
      "metadata": {
        "id": "tlkys1F-IaQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "The main task of an autoencoder is to find efficient representation of the input data can convert them to coding, without any supervision. Where coding is a lower dimensional \n",
        "representation of input data similar to dimensionality reduction is able to represent most of the data while being smaller in size.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "-CnWv9cEIaWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Suppose you want to train a classifier, and you have plenty of unlabeled training data but\n",
        "only a few thousand labeled instances. How can autoencoders help? How would you\n",
        "proceed?"
      ],
      "metadata": {
        "id": "BUL9ZbFjIbb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "What we can do in this case is using semi-supervised learning approach, we know autoencoders can learn efficient representation of input data meaning they can find \n",
        "various important patterns from input therefore we will train it with out unlabled data first where we use a Neural network as encoder, then using the weights obtained \n",
        "here we can intialize a neural network which already has some information about the input data and train it again using the labeled data that we have.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "XHhPIWLvIbb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If an autoencoder perfectly reconstructs the inputs, is it necessarily a good autoencoder?\n",
        "How can you evaluate the performance of an autoencoder?"
      ],
      "metadata": {
        "id": "cTSvY6ZZIbfj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "It might necessarily not be the case as it might actually be just copying the input data to output rather than generating the output. But conventionaly it will be considered \n",
        "as a good autoencoder if it is able to reconstruct the input perfectly, to make sure it is legit we can add noise to the input data to make the autoencoder robust. \n",
        "To evaluate its performance we can use the reconstruction loss.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "zPvi72JEIbfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are undercomplete and overcomplete autoencoders? What is the main risk of an\n",
        "excessively undercomplete autoencoder? What about the main risk of an overcomplete\n",
        "autoencoder?"
      ],
      "metadata": {
        "id": "LZEnW7KKIbi-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Undercomplete is when the dimension of embedding(coding layer) is less then the intput data and overcomplete is when it is more. The undercomplete one is for dimensionality \n",
        "reduction but just as any dimensionality reduction technique it might also fail to reconstruct the data if the representation is not that good. As for the overcomplete one \n",
        "the risk is the network might just copy the input data to output without learning anything.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "LF1diNSNIbi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How do you tie weights in a stacked autoencoder? What is the point of doing so?"
      ],
      "metadata": {
        "id": "eCsadyZlIbmL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "to tie weights of stacked autoencoder make a custom layer with weights that are transpose of the weights of encoder but will have its own bias vector and will act as a \n",
        "regular dense layer. It helps reducing the number of parameters of the model and thus reduces the training time as well as risk of overfitting.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "1TrmUpK8IbmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is a generative model? Can you name a type of generative autoencoder?"
      ],
      "metadata": {
        "id": "pTrtnsjIIbpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Generative models are those which are capable of generating new data instances based on the data they have been trained on. They include the distribution of data itself and can \n",
        "tell the likelihood of that given example.\n",
        "VAE or variational autoencoder is a type of generative model.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "LbO46D-cIbpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is a GAN? Can you name a few tasks where GANs can shine?"
      ],
      "metadata": {
        "id": "oCCKkFqAIbsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "It is a type of model in which 2 models compete with each other to become more acurate in their prediction. It uses unsupervised learing and use a cooperative zero-sum game \n",
        "framework to learn. The 2 models it uses are generator and discriminator, where generator is a convolutional neural network and discriminator is a deconvolutional neural network.\n",
        "The generator tries to learn the generation process of the given input data to be able to generate output similar to input data and discriminator is to identify the output \n",
        "as artificial or real.\n",
        "\n",
        "Can be used in:\n",
        "- image reconstruction\n",
        "- can be used for training a deep learning architecture using \"adversirial attack\" to make the model robust to cyber attacks. \n",
        "- can be used for 3d object creation\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "rc2e73bDIbsW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are the main difficulties when training GANs?"
      ],
      "metadata": {
        "id": "HOsxCV5vIbv4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "- setting up failure and bad initialization.\n",
        "- mode collapse\n",
        "- problem with counting\n",
        "- problem with global structure\n",
        "- problems with perspective\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "TdnBpXBXIbv5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}