{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "What are the pros and cons of using a stateful RNN versus a stateless RNN?"
      ],
      "metadata": {
        "id": "5_ync-TEbK52"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUlhBD45bGfV"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "In stateless RNNs we can capture patterns whose length is less or equal to the size of the window the RNN is trained on.\n",
        "Where as in stateful we can capture longer term patterns.\n",
        "\n",
        "The stateful RNN is difficult to implement and do not necessarily perform better because batches are not independent and identically distributed and we know \n",
        "gradient descent is not good with Non identically distrubuted data.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why do people use Encoderâ€“Decoder RNNs rather than plain sequence-to-sequence RNNs\n",
        "for automatic translation?"
      ],
      "metadata": {
        "id": "4KyS7MDzbL0m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8yl7pTnbL0n"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "As the translation using one word at a time is not that effective we use encoder-decoder rnns for translation.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How can you deal with variable-length input sequences? What about variable-length output\n",
        "sequences?"
      ],
      "metadata": {
        "id": "X5Alyz1ObL68"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtsp9hjhbL69"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "We can use the sequence_length parameter to deal with the variable length input sequence. Also we can pad the smaller once to make them of same size as larger ones.\n",
        "for variable length output we can set the sequence_length parameter if we know the output length beforhand, if not then padding would be the best and we can ignore the output \n",
        "after the end-of-sequence token.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is beam search and why would you use it? What tool can you use to implement it?"
      ],
      "metadata": {
        "id": "HOdeVtbfbL_k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "THmOTFqGbL_l"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "A heuristic search algorithm that examines a graph by extending the most promising node in a limited set is known as beam search. It uses breadth first serach \n",
        "and constructs its search tree, after than it generates all its sucessors of the current level's state at each level of the tree. Howeven, at each leve it only \n",
        "evaluates W number of states, other nodes are not taken into account, the cost associated with nodes is used to calculate the best nodes.\n",
        "Best to maintain the tractability in large systems with insufficient amount of memory to store the entive search tree. It is also used in machine translation as it \n",
        "generates target sentence word by word from left to right while keeping a fixed amount of active candidates at each time step.\n",
        "Neural machine translation (NMT) can be used to implement it.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is an attention mechanism? How does it help?"
      ],
      "metadata": {
        "id": "uYHoE2cMbMD2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SvqMW9KWbMD4"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Attention machanism means only paying attention to revelent features while ignoring the rest, this is based on human cognitive sense which also does the smae.\n",
        "It helps saving time generating the output, we get better output as non-revelant data does not affect the process.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the most important layer in the Transformer architecture? What is its purpose?"
      ],
      "metadata": {
        "id": "YcctNbjMbMHz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8eklxfvZbMH0"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "the most important part is the residual connections around the layers, as they are very important in order to retain the position realted information which are added \n",
        "to the input represetnation across the network.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When would you need to use sampled softmax?"
      ],
      "metadata": {
        "id": "Sfp_Gn3dbMLN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbCO0iY6bMLO"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "When the number of classes is very large we use sampled softmax which creates a sample of M < N classes in every update step. This aims to approximate a full softmax although \n",
        "its not possible but we try to be near the value as much as possible using way such as using sampling distribution closer to softmax, or more sample size m which is costly, etc.\n",
        "In sampled softmax instead of using all the classes at once we compute the loss over all classes using only the positive class and a sample of m negative classes. \n",
        "Here each negative class is sampled using probability qi with replacement.\n",
        "\"\"\""
      ]
    }
  ]
}