{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Can you think of a few applications for a sequence-to-sequence RNN? What about a\n",
        "sequence-to-vector RNN? And a vector-to-sequence RNN?"
      ],
      "metadata": {
        "id": "7PMSuQ5TC-1X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "1. Sequence to sequence RNNs are those in which we try to map the input sequence to an output sequence typically with the goal to predict the output sequence give the input \n",
        "sequence. Application inovolve machine translation, speech recognition, dialogue system, music generation, etc.\n",
        "\n",
        "2. Sequence to vector RNNs are those in which we try to map an input sequence to a fixed length vector representation, in order to find the key features or meaning of the \n",
        "input sequence. Applications include document summarization, sentiment analysis, named entity recognition, etc. \n",
        "\n",
        "3. Vector to sequence RNNs are those that are used to map a fixed length vector representation to an output sequence so as to generate an output sequence based on the vector.\n",
        "Applications include Text generation, music generation, diaglogue system, machine translation, etc.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "sTV1aCCKC-50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why do people use encoder–decoder RNNs rather than plain sequence-to-sequence RNNs\n",
        "for automatic translation?"
      ],
      "metadata": {
        "id": "a-q9R_rjDEk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "One of the key reasons is that encoder decoder RNNs allow the use of varying length input sequences where as in sequence to sequence RNN we need input and output to be of same \n",
        "length. The limitation is removed using a fixed length vector representation generation provision in the encoder for the input sequence where the encder processes the input one \n",
        "word by word and updates the hidden state at each time step then at the output or final hidden state we pass this final hidden state to the decoder as input which generates \n",
        "the output sequence word by word.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "YQSAC2eeDEk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How could you combine a convolutional neural network with an RNN to classify videos?"
      ],
      "metadata": {
        "id": "P85yIc-xDEpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "We know in the CNN the main thing it produces is the feature maps, so we can use CNN first to extract features from each frame of the video then use the RNN to precess the \n",
        "sequence of feature vector and make final classification.\n",
        "\n",
        "steps:\n",
        "1. first split the video into frames and usee CNN to extract a feature vector.\n",
        "2. then use RNN to process the sequence of feature vectors, updating the hidden state at each time step based on the input feature and the previous hidden state.\n",
        "3. then we use the final hidden state of the RNN as input to a fully connected layer that procuced a prediction for the classification.\n",
        "4. An we train the CNN and RNN end-to-end using a labeled dataset of videos.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "62W2wrtEDEpB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are the advantages of building an RNN using dynamic_rnn() rather than static_rnn()?"
      ],
      "metadata": {
        "id": "2f7MxYo4DEtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "These 2 are the methods available for building RNN to precess sequential data. The advantage of dynamic_rnn is that it can handle input sequences of variable length while \n",
        "static_rnn cannot as it requies fixed length input sequences. So it makes dynamic rnn more flexible and easier for real world applications. Also the memory usage of the dynamic_rnn\n",
        "is also efficient as well as its computation as it does not need to allocate memory for the full input sequence upfront.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "iBREK7H8DEtW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "How can you deal with variable-length input sequences? What about variable-length output\n",
        "sequences?"
      ],
      "metadata": {
        "id": "stljhU3QDEwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "variable-length input sequences:\n",
        "1. can be dealth with using the dynamic_rnn which is designed to work with variable length input sequences.\n",
        "2. we can use padding to make sure the input sequence remains fixed. This is done in static_rnn\n",
        "3. We can also use the sequence masking in dynamic rnn which allows us to specify a sequence of mask that indicates which time step in the input sequnce should be ignored. \n",
        "so we can just mask out the dummy time steps added for padding.\n",
        "4. We can use encoder-decoder rnn or the transformers as the are designed to handle these variable length seqeunces and do not require padding.\n",
        "\n",
        "variable-length output sequence:\n",
        "1. use dynamic_rnn as it does not requires the output sequences to be of same length\n",
        "2. use the transformers\n",
        "3. use sequence to sequence models as they are used to handle fixed input sequences and map them to fixed output sequences so the output will be of same length.\n",
        "4. we can make use of padding or masking.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "B4A_xf14DEwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is a common way to distribute training and execution of a deep RNN across multiple\n",
        "GPUs?"
      ],
      "metadata": {
        "id": "vsT3y1uzDE0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "One way is data parallelism we can split the data into smaller batches and each batch is processed on separate GPU. The gradient of them is then averaged across the GPUs and \n",
        "used to update the model parameters. For applying this we use the tf.distribute.Strategy API which provides high-level interface for disctributing training across multiple \n",
        "machines.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "BIXIndHhDE0a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}